# ü§ñ Guide : Changer l'API du Chatbot

## üìã Table des mati√®res
1. [Comprendre l'architecture actuelle](#architecture-actuelle)
2. [√âtapes pour changer l'API](#√©tapes-changement)
3. [Exemples d'APIs alternatives](#apis-alternatives)
4. [Configuration et tests](#configuration-tests)

---

## üèóÔ∏è Architecture Actuelle {#architecture-actuelle}

Votre chatbot utilise actuellement **Google Gemini AI** avec l'architecture suivante :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend       ‚îÇ
‚îÇ  (Chatbot.jsx)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Django API     ‚îÇ
‚îÇ  (views.py)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Bot Brain      ‚îÇ
‚îÇ (bot_intelligence.py)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Gemini AI      ‚îÇ
‚îÇ (gemini_intelligence.py)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fichiers concern√©s :
- **`chatbot/views.py`** : Point d'entr√©e API (endpoints REST)
- **`chatbot/bot_intelligence.py`** : Logique m√©tier du chatbot
- **`chatbot/gemini_intelligence.py`** : Int√©gration avec Gemini AI
- **`frontend/travelbook/src/components/Chatbot.jsx`** : Interface utilisateur

---

## üîÑ √âtapes pour Changer l'API {#√©tapes-changement}

### **√âtape 1 : Choisir votre nouvelle API**

Voici quelques alternatives populaires :

| API | Avantages | Inconv√©nients |
|-----|-----------|---------------|
| **OpenAI (GPT-4)** | Tr√®s performant, documentation excellente | Payant, quota limit√© |
| **Anthropic Claude** | Excellent pour conversations longues | Payant |
| **Mistral AI** | Fran√ßais, performant, moins cher | Moins connu |
| **Hugging Face** | Gratuit, open-source | N√©cessite h√©bergement |
| **Cohere** | Bon rapport qualit√©/prix | Moins de fonctionnalit√©s |

---

### **√âtape 2 : Cr√©er un nouveau fichier d'intelligence**

Cr√©ez un fichier pour votre nouvelle API (exemple avec OpenAI) :

**Fichier : `chatbot/openai_intelligence.py`**

```python
"""
Intelligence du chatbot avec OpenAI GPT
"""

import os
import json
import requests
from django.conf import settings


class OpenAIChatbot:
    """Chatbot intelligent utilisant l'API OpenAI"""
    
    def __init__(self):
        # R√©cup√©rer la cl√© API
        self.api_key = os.getenv('OPENAI_API_KEY', getattr(settings, 'OPENAI_API_KEY', None))
        
        if not self.api_key:
            print("[WARNING] Cl√© API OpenAI manquante")
            self.api_key = None
            
        # URL de l'API OpenAI
        self.api_url = "https://api.openai.com/v1/chat/completions"
        
        # Contexte du chatbot
        self.system_context = """
Tu es TravelTodo Assistant, un assistant de voyage intelligent.

Ton r√¥le:
- Aider avec les h√¥tels, vols et circuits
- Comprendre les besoins des utilisateurs
- √ätre chaleureux et professionnel

Format de r√©ponse (JSON):
{
    "intent": "search_hotel|search_flight|search_package|greeting|help|thanks|unknown",
    "entities": {
        "destination": "ville/pays",
        "budget": nombre,
        "stars": nombre (1-5)
    },
    "response": "r√©ponse conversationnelle",
    "confidence": 0.0-1.0
}
"""
    
    def _call_openai_api(self, prompt_text):
        """Appel √† l'API OpenAI"""
        if not self.api_key:
            raise ValueError("Cl√© API manquante")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        data = {
            "model": "gpt-4",  # ou "gpt-3.5-turbo" pour moins cher
            "messages": [
                {"role": "system", "content": self.system_context},
                {"role": "user", "content": prompt_text}
            ],
            "temperature": 0.7,
            "max_tokens": 800
        }
        
        try:
            response = requests.post(
                self.api_url,
                headers=headers,
                json=data,
                timeout=10
            )
            
            response.raise_for_status()
            result = response.json()
            
            # Extraire le texte de la r√©ponse
            if 'choices' in result and result['choices']:
                return result['choices'][0]['message']['content']
            return None
            
        except Exception as e:
            print(f"Erreur appel API OpenAI: {e}")
            return None

    def analyze_message(self, user_message, conversation_history=None):
        """Analyse un message utilisateur"""
        try:
            # Construire le prompt
            prompt = f"Message utilisateur: {user_message}\n"
            prompt += "Analyse ce message et r√©ponds avec le JSON demand√©."
            
            # Appel API
            response_text = self._call_openai_api(prompt)
            
            if response_text:
                return self._parse_response(response_text)
            
            raise Exception("Pas de r√©ponse de l'API")
            
        except Exception as e:
            print(f"Erreur OpenAI: {e}")
            return self._fallback_analysis(user_message)
    
    def generate_conversational_response(self, user_message, conversation_history=None):
        """G√©n√®re une r√©ponse conversationnelle"""
        try:
            prompt = f"""
R√©ponds de mani√®re naturelle et chaleureuse.
Message utilisateur: {user_message}
"""
            response_text = self._call_openai_api(prompt)
            
            if response_text:
                return response_text.strip()
                
            return "Je suis l√† pour vous aider ! Que recherchez-vous ?"
            
        except Exception as e:
            print(f"Erreur g√©n√©ration r√©ponse: {e}")
            return "Comment puis-je vous aider ?"

    def _parse_response(self, response_text):
        """Parse la r√©ponse JSON"""
        try:
            cleaned = response_text.strip()
            if cleaned.startswith('```json'): cleaned = cleaned[7:]
            if cleaned.startswith('```'): cleaned = cleaned[3:]
            if cleaned.endswith('```'): cleaned = cleaned[:-3]
            
            analysis = json.loads(cleaned.strip())
            
            return {
                'intent': analysis.get('intent', 'unknown'),
                'entities': analysis.get('entities', {}),
                'response': analysis.get('response', ''),
                'confidence': float(analysis.get('confidence', 0.5))
            }
        except Exception:
            return {
                'intent': 'unknown',
                'entities': {},
                'response': response_text[:200],
                'confidence': 0.5
            }

    def _fallback_analysis(self, user_message):
        """Fallback simple"""
        msg = user_message.lower()
        if any(w in msg for w in ['bonjour', 'salut']):
            return {
                'intent': 'greeting',
                'response': 'Bonjour ! O√π souhaitez-vous partir ?',
                'entities': {},
                'confidence': 1.0
            }
        return {
            'intent': 'unknown',
            'response': 'Je peux vous aider √† trouver des h√¥tels ou des vols.',
            'entities': {},
            'confidence': 0.5
        }

    def generate_response_with_recommendations(self, intent, entities, recommendations):
        """G√©n√®re une r√©ponse avec recommandations"""
        try:
            count = len(recommendations)
            prompt = f"""
L'utilisateur a cherch√©: {intent}
R√©sultats trouv√©s: {count}

G√©n√®re une phrase courte et engageante pour pr√©senter ces r√©sultats.
"""
            response = self._call_openai_api(prompt)
            if response:
                return response.strip()
            return f"J'ai trouv√© {count} r√©sultats pour vous !"
        except:
            return f"Voici {len(recommendations)} r√©sultats correspondants."
```

---

### **√âtape 3 : Modifier `bot_intelligence.py`**

Modifiez l'import dans le fichier `chatbot/bot_intelligence.py` :

**Avant :**
```python
# Import de l'intelligence Gemini
try:
    from .gemini_intelligence import GeminiChatbot
    GEMINI_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è Gemini non disponible: {e}")
    GEMINI_AVAILABLE = False
```

**Apr√®s :**
```python
# Import de l'intelligence OpenAI (ou autre)
try:
    from .openai_intelligence import OpenAIChatbot  # ‚Üê Changement ici
    AI_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è OpenAI non disponible: {e}")
    AI_AVAILABLE = False
```

Puis modifiez l'initialisation dans la classe `ChatbotBrain` :

**Avant :**
```python
def __init__(self):
    # Initialiser Gemini si disponible
    self.gemini = None
    if GEMINI_AVAILABLE:
        try:
            self.gemini = GeminiChatbot()
            print("‚úÖ Gemini AI activ√©!")
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible d'initialiser Gemini: {e}")
            self.gemini = None
```

**Apr√®s :**
```python
def __init__(self):
    # Initialiser OpenAI si disponible
    self.ai_engine = None  # ‚Üê Renommer pour √™tre g√©n√©rique
    if AI_AVAILABLE:
        try:
            self.ai_engine = OpenAIChatbot()  # ‚Üê Changement ici
            print("‚úÖ OpenAI activ√©!")
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible d'initialiser OpenAI: {e}")
            self.ai_engine = None
```

Ensuite, remplacez toutes les r√©f√©rences √† `self.gemini` par `self.ai_engine` :

**Exemple :**
```python
# Avant
if self.gemini:
    try:
        analysis = self.gemini.analyze_message(message)

# Apr√®s
if self.ai_engine:
    try:
        analysis = self.ai_engine.analyze_message(message)
```

---

### **√âtape 4 : Configurer les variables d'environnement**

Cr√©ez ou modifiez le fichier `.env` √† la racine du projet :

```bash
# Ancienne configuration (Gemini)
# GEMINI_API_KEY=votre-ancienne-cl√©

# Nouvelle configuration (OpenAI)
OPENAI_API_KEY=sk-votre-cl√©-openai-ici
```

**Pour obtenir une cl√© API OpenAI :**
1. Allez sur https://platform.openai.com/
2. Cr√©ez un compte
3. Allez dans "API Keys"
4. Cr√©ez une nouvelle cl√©
5. Copiez-la dans votre `.env`

---

### **√âtape 5 : Mettre √† jour `settings.py`**

Dans `travel-todo/travel_todo/settings.py`, ajoutez :

```python
# Configuration API Chatbot
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'your-openai-api-key-here')

# Ou pour garder la compatibilit√© avec Gemini
# GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'your-gemini-api-key-here')
```

---

### **√âtape 6 : Installer les d√©pendances**

Si n√©cessaire, installez les biblioth√®ques requises :

```bash
pip install openai  # Pour OpenAI
# ou
pip install anthropic  # Pour Claude
# ou
pip install mistralai  # Pour Mistral
```

Mettez √† jour `requirements.txt` :
```bash
pip freeze > requirements.txt
```

---

### **√âtape 7 : Tester le chatbot**

1. **Red√©marrez le serveur Django :**
```bash
python manage.py runserver
```

2. **Testez via l'interface frontend** ou **via curl** :

```bash
curl -X POST http://localhost:8000/api/chatbot/send_message/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Je cherche un h√¥tel √† Paris"
  }'
```

3. **V√©rifiez les logs** pour voir si l'API est bien appel√©e :
```
‚úÖ OpenAI activ√©!
```

---

## üîå APIs Alternatives {#apis-alternatives}

### **Option 1 : OpenAI GPT**

**Fichier :** `openai_intelligence.py` (voir exemple ci-dessus)

**Avantages :**
- Tr√®s performant
- Documentation excellente
- Supporte GPT-4 et GPT-3.5-turbo

**Configuration :**
```python
OPENAI_API_KEY=sk-...
```

---

### **Option 2 : Anthropic Claude**

**Fichier :** `claude_intelligence.py`

```python
import anthropic

class ClaudeChatbot:
    def __init__(self):
        self.client = anthropic.Anthropic(
            api_key=os.getenv('ANTHROPIC_API_KEY')
        )
    
    def _call_claude_api(self, prompt_text):
        message = self.client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=1024,
            messages=[
                {"role": "user", "content": prompt_text}
            ]
        )
        return message.content[0].text
```

**Configuration :**
```bash
pip install anthropic
```

---

### **Option 3 : Mistral AI**

**Fichier :** `mistral_intelligence.py`

```python
from mistralai.client import MistralClient

class MistralChatbot:
    def __init__(self):
        self.client = MistralClient(
            api_key=os.getenv('MISTRAL_API_KEY')
        )
    
    def _call_mistral_api(self, prompt_text):
        response = self.client.chat(
            model="mistral-large-latest",
            messages=[
                {"role": "user", "content": prompt_text}
            ]
        )
        return response.choices[0].message.content
```

**Configuration :**
```bash
pip install mistralai
```

---

### **Option 4 : Hugging Face (Gratuit)**

**Fichier :** `huggingface_intelligence.py`

```python
from transformers import pipeline

class HuggingFaceChatbot:
    def __init__(self):
        self.generator = pipeline(
            'text-generation',
            model='mistralai/Mistral-7B-Instruct-v0.1'
        )
    
    def _call_hf_api(self, prompt_text):
        result = self.generator(
            prompt_text,
            max_length=500,
            num_return_sequences=1
        )
        return result[0]['generated_text']
```

**Configuration :**
```bash
pip install transformers torch
```

---

## ‚úÖ Configuration et Tests {#configuration-tests}

### **Checklist de migration**

- [ ] Cr√©er le nouveau fichier d'intelligence (ex: `openai_intelligence.py`)
- [ ] Modifier les imports dans `bot_intelligence.py`
- [ ] Renommer `self.gemini` en `self.ai_engine`
- [ ] Mettre √† jour toutes les r√©f√©rences
- [ ] Ajouter la cl√© API dans `.env`
- [ ] Mettre √† jour `settings.py`
- [ ] Installer les d√©pendances
- [ ] Tester avec le serveur Django
- [ ] V√©rifier les logs
- [ ] Tester via l'interface frontend

---

### **Tests unitaires**

Cr√©ez un fichier de test : `chatbot/test_new_api.py`

```python
from django.test import TestCase
from .openai_intelligence import OpenAIChatbot

class OpenAIChatbotTest(TestCase):
    def setUp(self):
        self.chatbot = OpenAIChatbot()
    
    def test_analyze_message(self):
        result = self.chatbot.analyze_message("Je cherche un h√¥tel √† Paris")
        self.assertIn('intent', result)
        self.assertIn('entities', result)
        print(f"‚úÖ Test r√©ussi: {result}")

    def test_conversational_response(self):
        response = self.chatbot.generate_conversational_response("Bonjour")
        self.assertIsInstance(response, str)
        self.assertTrue(len(response) > 0)
        print(f"‚úÖ R√©ponse: {response}")
```

**Lancer les tests :**
```bash
python manage.py test chatbot.test_new_api
```

---

### **Debugging**

Si vous rencontrez des probl√®mes :

1. **V√©rifier la cl√© API :**
```python
import os
print(os.getenv('OPENAI_API_KEY'))
```

2. **Activer les logs d√©taill√©s :**
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

3. **Tester l'API directement :**
```python
from chatbot.openai_intelligence import OpenAIChatbot
bot = OpenAIChatbot()
result = bot.analyze_message("test")
print(result)
```

---

## üéØ R√©sum√©

Pour changer l'API du chatbot :

1. **Cr√©er** un nouveau fichier d'intelligence (ex: `openai_intelligence.py`)
2. **Modifier** les imports dans `bot_intelligence.py`
3. **Configurer** la cl√© API dans `.env`
4. **Tester** le chatbot
5. **D√©ployer** les changements

**Temps estim√© :** 30-60 minutes

---

## üìö Ressources

- [Documentation OpenAI](https://platform.openai.com/docs)
- [Documentation Anthropic Claude](https://docs.anthropic.com)
- [Documentation Mistral AI](https://docs.mistral.ai)
- [Hugging Face Models](https://huggingface.co/models)

---

**Cr√©√© le :** 2025-12-08  
**Auteur :** TravelTodo Team  
**Version :** 1.0
